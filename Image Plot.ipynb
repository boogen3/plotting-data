{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial test of data plotting\n",
    "- Early stage build of a project. \n",
    "- This is a test at pulling images from a h5 file and displaying them.\n",
    "- Future projects will use a modified version of this code. \n",
    "\n",
    "The data used is from Oak Ridge National Labratory<br>\n",
    "**Big Data Analytics for Scanning Transmission Electron Microscopy Ptychography**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using this program\n",
    "\n",
    "To use this program, you need to have the h5 file saved to your device where this is running. <br>\n",
    "**You will need to install pycroscopy if you do not already have it installed.**<br>\n",
    "Note: pip install pycroscopy will work if your system is configured for such a command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initilaization\n",
    "\n",
    "The code will import the required packages as well as allow for the import of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Requirement already up-to-date: pyUSID==0.0.4 in d:\\booge\\anaconda3\\lib\\site-packages (0.0.4)\n",
      "Requirement already up-to-date: pycroscopy==0.60.1 in d:\\booge\\anaconda3\\lib\\site-packages (0.60.1)\n"
     ]
    }
   ],
   "source": [
    "# System check\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} numpy scipy matplotlib scikit-learn Ipython ipywidgets h5py\n",
    "!{sys.executable} -m pip install -U --no-deps pyUSID==0.0.4\n",
    "!{sys.executable} -m pip install -U --no-deps pycroscopy==0.60.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sys.path.append('..')\n",
    "import pyUSID as usid\n",
    "import pycroscopy as px\n",
    "\n",
    "# Make Notebook take up most of page width\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "# set up notebook to show plots within the notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "\n",
    "This will create a popup window for the user to select and load in the h5 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on:\n",
      "C:/Users/booge/Documents/Globus/62.tar/62/20120212_21_GB.h5\n"
     ]
    }
   ],
   "source": [
    "# The user will select the location of the data\n",
    "h5_path = px.io_utils.file_dialog('*.h5', '4D STEM dataset formatted according to USID')\n",
    "print('Working on:\\n' + h5_path)\n",
    "# Open the file\n",
    "h5_file = h5py.File(h5_path, mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data\n",
    "\n",
    "This section does the following three things\n",
    "- Selects the dataset containing the raw data\n",
    "- Converts the data from a HDF5 sataset to a USIDataset\n",
    "- Reads the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "├ Measurement_000\n",
      "  ---------------\n",
      "  ├ Mean_Ronchigram\n",
      "  ├ Position_Indices\n",
      "  ├ Position_Labels\n",
      "  ├ Position_Values\n",
      "  ├ Ptychography_Data\n",
      "  ├ Spectroscopic_Indices\n",
      "  ├ Spectroscopic_Labels\n",
      "  ├ Spectroscopic_Mean\n",
      "  ├ Spectroscopic_Values\n"
     ]
    }
   ],
   "source": [
    "usid.hdf_utils.print_tree(h5_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error present\n",
    "\n",
    "There is currently an issue with this code that will not allow it to pass beyond this step. <br>\n",
    "According to the tree you will see generated, there is no Raw_Data file included in the h5. <br>\n",
    "I need to learn if there is another way to deal with the data, or if the issue is that the origional program wrote over the data file. <br>\n",
    "The origional program had r+ mode for the file and not just r. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a94016d3df34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Select the dataset containing the raw data to start working with:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mh5_main\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Raw_Data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Upgrade this object from a regular HDF5 dataset to a USIDataset:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mh5_main\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUSIDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5_main\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Select the dataset containing the raw data to start working with:\n",
    "h5_main = usid.hdf_utils.find_dataset(h5_file, 'Raw_Data')[-1]\n",
    "\n",
    "# Upgrade this object from a regular HDF5 dataset to a USIDataset:\n",
    "h5_main = usid.USIDataset(h5_main)\n",
    "\n",
    "# Read some necessary parameters:\n",
    "h5_pos_inds = h5_main.h5_pos_inds\n",
    "num_rows, num_cols = h5_main.pos_dim_sizes\n",
    "h5_spec_inds = h5_main.h5_spec_inds\n",
    "num_sensor_rows, num_sensor_cols = h5_main.spec_dim_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Ronchigrams\n",
    "\n",
    "The raw ronchigrams are plotted in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_row = int(0.5*num_rows)\n",
    "coarse_col = int(0.5*num_cols)\n",
    "coarse_pos = coarse_row * num_rows + coarse_col\n",
    "\n",
    "current_ronch = np.reshape(h5_main[coarse_pos], (num_sensor_rows, num_sensor_cols))\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(14,7))\n",
    "axes[0].hold(True)\n",
    "axes[0].set_title('Mean Response')\n",
    "main_map = axes[0].imshow(np.reshape(h5_main.parent['Spectroscopic_Mean'], (num_rows, num_cols)), \n",
    "                          cmap=px.plot_utils.cmap_jet_white_center(), origin='lower')\n",
    "main_vert_line = axes[0].axvline(x=coarse_col, color='k')\n",
    "main_hor_line = axes[0].axhline(y=coarse_row, color='k')\n",
    "axes[1].set_title('Ronchigram at current pixel')\n",
    "img_zoom = axes[1].imshow(current_ronch,cmap=px.plot_utils.cmap_jet_white_center(), origin='lower')\n",
    "\n",
    "def move_zoom_box(event):\n",
    "    if not main_map.axes.in_axes(event):\n",
    "        return\n",
    "    \n",
    "    coarse_col = int(round(event.xdata))\n",
    "    coarse_row = int(round(event.ydata))\n",
    "    main_vert_line.set_xdata(coarse_col)\n",
    "    main_hor_line.set_ydata(coarse_row)\n",
    "    \n",
    "    coarse_pos = coarse_row * num_rows + coarse_col\n",
    "    current_ronch = np.reshape(h5_main[coarse_pos], (num_sensor_rows, num_sensor_cols))\n",
    "\n",
    "    img_zoom.set_data(current_ronch)\n",
    "    #img_zoom.set_clim(vmax=ronch_max, vmin=ronch_min)\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "\n",
    "cid = main_map.figure.canvas.mpl_connect('button_press_event', move_zoom_box)\n",
    "# widgets.interact(move_zoom_box, coarse_row=(0, num_rows, 1), \n",
    "#                  coarse_col=(0, num_cols, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Value Decomposition\n",
    "\n",
    "Here we perform some basic linear algebra to get the eigenvectors and eigenvalues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose how many components you want\n",
    "num_svd_comps = 256\n",
    "\n",
    "proc = px.processing.SVD(h5_main, num_components=num_svd_comps)\n",
    "\n",
    "h5_svd_group = proc.compute()\n",
    "    \n",
    "h5_u = h5_svd_group['U']\n",
    "h5_v = h5_svd_group['V']\n",
    "h5_s = h5_svd_group['S']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD Visualization\n",
    "\n",
    "The varience, eigenvalues, and eigenvectors are visaulized. \n",
    "- S is the varience\n",
    "- U is the eigenvalues\n",
    "- V is the eigenvectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose how many components of U and V to display\n",
    "num_plot_comps = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize variance of the principal components\n",
    "fig, axes = usid.plot_utils.plot_scree(h5_s, title='Variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the abundance maps from SVD:\n",
    "loadings = np.reshape(h5_u[:, :num_plot_comps], (num_rows, num_cols, -1)).transpose([2, 0, 1])\n",
    "fig, axes = usid.plot_utils.plot_map_stack(loadings, num_comps=num_plot_comps, title='Abundance Maps',\n",
    "                                         cmap=px.plot_utils.cmap_jet_white_center())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Endmembers from SVD:\n",
    "eigenvectors = np.reshape(h5_v[:num_plot_comps], (-1, num_sensor_rows, num_sensor_cols))\n",
    "fig, axes = usid.plot_utils.plot_map_stack(eigenvectors, num_comps=num_plot_comps, title='Endmembers',\n",
    "                                         cmap=px.plot_utils.cmap_jet_white_center())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Here, the varience is lmited and the data is clustered according to the varience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose how many SVD components to use in clustering\n",
    "spectral_components = 128\n",
    "# Choose how many clusters to use\n",
    "num_clusters = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "proc = px.processing.Cluster(h5_u, estimator, num_comps=spectral_components)\n",
    "\n",
    "h5_kmeans_group = proc.compute()\n",
    "    \n",
    "h5_labels = h5_kmeans_group['Labels']\n",
    "h5_centroids = h5_kmeans_group['Mean_Response']\n",
    "\n",
    "# In case we take existing results, we need to get these parameters\n",
    "num_comps_for_clustering = h5_centroids.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mat = np.reshape(h5_labels, (num_rows, num_cols))\n",
    "fig, axes = px.viz.cluster_utils.plot_cluster_labels(label_mat, num_clusters=num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_vals = np.reshape(h5_u[:, :spectral_components], \n",
    "                    (num_rows, num_cols, -1))\n",
    "fig = px.viz.cluster_utils.plot_cluster_dendrogram(label_mat, e_vals, \n",
    "                                                   num_comps_for_clustering, \n",
    "                                                   num_clusters, \n",
    "                                                   last=num_clusters);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
